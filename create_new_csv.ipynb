{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T15:46:59.485167Z",
     "start_time": "2025-05-12T15:46:58.631808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from meteostat import Point, Daily\n",
    "from meteostat import Hourly\n",
    "import holidays\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def filter_holidays(holidays, start_date, end_date):\n",
    "    start_ts = pd.Timestamp(start_date)\n",
    "    end_ts = pd.Timestamp(end_date)\n",
    "\n",
    "    return {\n",
    "        date_key: holiday_name\n",
    "        for date_key, holiday_name in holidays.items()\n",
    "        if start_ts <= pd.Timestamp(date_key) <= end_ts\n",
    "    }\n",
    "\n",
    "def mark_special_days(df, holidays_df):\n",
    "    # Create time mask for 7am to 1pm\n",
    "    market_time = (df['timestamp'].dt.hour >= 7) & (df['timestamp'].dt.hour < 13)\n",
    "    # Create day mask for Wednesdays and Saturdays\n",
    "    market_day = df['timestamp'].dt.day_name().isin(['Wednesday', 'Saturday'])\n",
    "\n",
    "    # Create column for Wednesdays and Saturdays\n",
    "    df['market_day'] = (market_day & market_time).astype(int)\n",
    "\n",
    "   # Create a temporary series for holidays that fall on Thursday\n",
    "    #thursday_holidays = (df['timestamp'].dt.date.isin(holidays_df.date_holiday)) & (df['timestamp'].dt.day_name() == 'Thursday')\n",
    "    holidays_df['date'] = pd.to_datetime(holidays_df['date_holiday'])\n",
    "\n",
    "    thursday_holidays = holidays_df[holidays_df['date'].dt.day_name() == 'Thursday']\n",
    "    # Mark Fridays that follow a Thursday holiday\n",
    "    df['special_friday'] = ((df['timestamp']-timedelta(days=1)).dt.date.isin(thursday_holidays['date'].dt.date) & (df['timestamp'].dt.day_name() == 'Friday')).astype(int)\n",
    "    #df['special_friday'] = thursday_holidays.shift(-1) & (df['timestamp'].dt.day_name() == 'Friday')\n",
    "    #df['special_friday'] = df['special_friday'].astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "data = pd.read_csv('./data/stadtgarage.csv')\n",
    "events_df = pd.read_excel('./data/events.xlsx')\n",
    "events_df['Date'] = pd.to_datetime(events_df['Date'])\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp')\n",
    "start_date = pd.to_datetime('2023-11-30')\n",
    "end_date = pd.to_datetime('2024-11-12')\n",
    "df = df[(df['timestamp'] >= start_date) & (df['timestamp'] <= end_date)]\n",
    "df = df[df['measurement_name'] == 'utilization']\n",
    "\n",
    "austria_holidays = holidays.country_holidays('AT', subdiv='V', years=range(df['timestamp'].min().year, df['timestamp'].max().year+1))\n",
    "filtered_holidays = filter_holidays(austria_holidays, start_date, end_date)\n",
    "holidays_df = pd.DataFrame({'date_holiday': list(filtered_holidays.keys()), 'holiday': 'holiday'})\n",
    "holidays_df = holidays_df.sort_values('date_holiday')\n",
    "# Define the coordinates for Dornbirn, Austria\n",
    "point = Point(47.4145, 9.7381)\n",
    "\n",
    "weather_data_hourly = Hourly(point, start_date, end_date)\n",
    "weather_data_hourly = weather_data_hourly.fetch()\n",
    "weather_data_daily = Daily(point, start_date, end_date)\n",
    "weather_data_daily = weather_data_daily.fetch()\n",
    "\n",
    "\n",
    "weather_daily_cols = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wspd', 'wpgt', 'pres']\n",
    "# Reset index of weather data to make 'time' a regular column\n",
    "weather_daily = weather_data_daily[weather_daily_cols].reset_index()\n",
    "weather_hourly_cols = ['temp', 'dwpt', 'rhum', 'prcp', 'wspd', 'wpgt', 'pres', 'tsun']\n",
    "weather_hourly = weather_data_hourly[weather_hourly_cols].reset_index()\n",
    "\n",
    "# Round your original df timestamps to the nearest hour for matching\n",
    "df['hour_timestamp'] = df['timestamp'].dt.floor('h')\n",
    "df['hour_timestamp'] = pd.to_datetime(df['hour_timestamp'])\n",
    "# Create a date column for merging\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['date_holiday'] = df['timestamp'].dt.date\n",
    "df['date_event'] = df['timestamp'].dt.date\n",
    "df['date_event'] = pd.to_datetime(df['date_event'])\n",
    "\n",
    "weather_daily['time'] = weather_daily['time'].dt.date\n",
    "# Merge using broadcast join\n",
    "df = pd.merge_ordered(df, holidays_df, fill_method=\"ffill\", left_by=\"date_holiday\")\n",
    "df = df.merge(weather_daily, left_on='date', right_on='time', how='left')\n",
    "df = df.merge(weather_hourly, left_on='hour_timestamp',right_on='time',how='left')\n",
    "\n",
    "df = df.merge(events_df, left_on='date_event', right_on='Date', how='left')\n",
    "df = mark_special_days(df, holidays_df)\n",
    "# Clean up if needed\n",
    "df = df.drop('sensor_id', axis=1)\n",
    "df = df.drop('date_holiday', axis=1)\n",
    "df = df.drop('date_event', axis=1)\n",
    "df = df.drop('time_x', axis=1)\n",
    "df = df.drop('time_y', axis=1)\n",
    "df = df.drop('Date', axis=1)\n",
    "df = df.drop('date', axis=1)\n",
    "df = df.drop('measurement_name', axis=1)\n",
    "df_hour = df.groupby('hour_timestamp')['value'].mean().reset_index()\n",
    "df = df.merge(df_hour, left_on='hour_timestamp', right_on='hour_timestamp', how='left')\n",
    "\n",
    "df = df.drop('timestamp', axis=1)\n",
    "df = df.drop('value_x', axis=1)\n",
    "\n",
    "df = df.drop_duplicates(subset=['hour_timestamp'], keep='first')\n",
    "\n",
    "# Einzelne oder mehrere Spalten umbenennen\n",
    "df = df.rename(columns={'hour_timestamp': 'timestamp', 'value_y': 'value'})\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('data/out_hourly.csv', index=False)"
   ],
   "id": "2bfe63fd1b640c6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp holiday  tavg  tmin  tmax  prcp_x  snow  wspd_x  \\\n",
      "0     2023-11-30 00:00:00     NaN   0.8  -1.4   3.9    16.4   0.0     3.4   \n",
      "7     2023-11-30 01:00:00     NaN   0.8  -1.4   3.9    16.4   0.0     3.4   \n",
      "14    2023-11-30 02:00:00     NaN   0.8  -1.4   3.9    16.4   0.0     3.4   \n",
      "21    2023-11-30 03:00:00     NaN   0.8  -1.4   3.9    16.4   0.0     3.4   \n",
      "29    2023-11-30 04:00:00     NaN   0.8  -1.4   3.9    16.4   0.0     3.4   \n",
      "...                   ...     ...   ...   ...   ...     ...   ...     ...   \n",
      "58019 2024-11-11 11:00:00     NaN   6.8   5.7   7.7     4.6   0.0     3.1   \n",
      "58026 2024-11-11 12:00:00     NaN   6.8   5.7   7.7     4.6   0.0     3.1   \n",
      "58033 2024-11-11 13:00:00     NaN   6.8   5.7   7.7     4.6   0.0     3.1   \n",
      "58041 2024-11-11 14:00:00     NaN   6.8   5.7   7.7     4.6   0.0     3.1   \n",
      "58048 2024-11-11 15:00:00     NaN   6.8   5.7   7.7     4.6   0.0     3.1   \n",
      "\n",
      "       wpgt_x  pres_x  ...  rhum  prcp_y  wspd_y  wpgt_y  pres_y  tsun  \\\n",
      "0        32.8  1002.5  ...  96.0     0.0     7.2    14.8  1006.6   0.0   \n",
      "7        32.8  1002.5  ...  96.0     0.0     3.6    15.1  1005.8   0.0   \n",
      "14       32.8  1002.5  ...  93.0     0.0     3.6     9.4  1005.4   0.0   \n",
      "21       32.8  1002.5  ...  87.0     0.0     0.0    11.2  1004.8   0.0   \n",
      "29       32.8  1002.5  ...  86.0     0.0     3.6    10.1  1004.3   0.0   \n",
      "...       ...     ...  ...   ...     ...     ...     ...     ...   ...   \n",
      "58019    19.4  1028.5  ...  80.0     0.0     3.6    13.0  1029.4   0.0   \n",
      "58026    19.4  1028.5  ...  84.0     0.0     3.6    13.0  1029.0   0.0   \n",
      "58033    19.4  1028.5  ...  82.0     0.0     3.6    19.4  1028.0   0.0   \n",
      "58041    19.4  1028.5  ...  81.0     0.0     3.6    18.0  1027.7   0.0   \n",
      "58048    19.4  1028.5  ...  81.0     0.0     3.6     8.6  1027.3   0.0   \n",
      "\n",
      "                        event_name  market_day special_friday       value  \n",
      "0                Christkindlemarkt           0              0   94.000000  \n",
      "7                Christkindlemarkt           0              0   91.142857  \n",
      "14               Christkindlemarkt           0              0   89.000000  \n",
      "21               Christkindlemarkt           0              0   89.000000  \n",
      "29               Christkindlemarkt           0              0   89.000000  \n",
      "...                            ...         ...            ...         ...  \n",
      "58019  Faschingsauftakt Innenstadt           0              0  328.857143  \n",
      "58026  Faschingsauftakt Innenstadt           0              0  257.857143  \n",
      "58033  Faschingsauftakt Innenstadt           0              0  240.375000  \n",
      "58041  Faschingsauftakt Innenstadt           0              0  262.428571  \n",
      "58048  Faschingsauftakt Innenstadt           0              0  272.000000  \n",
      "\n",
      "[8094 rows x 22 columns]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4241fb7f7d3d7c35"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
